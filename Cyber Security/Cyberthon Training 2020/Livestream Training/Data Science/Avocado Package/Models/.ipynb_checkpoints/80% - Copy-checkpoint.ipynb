{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avocado Data Analysis Notebook\n",
    "ALT-TAB LABS LLP &copy; 2020 All Rights Reserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['75%.py',\n '80% - Copy.ipynb',\n '80%-One Hot Encoding & Imputing.ipynb',\n '83%-Datetime Conversion.ipynb',\n 'avocado-submission.csv',\n 'avocado-test.csv',\n 'avocado-train.csv',\n 'avocado_notebook_other_models.ipynb',\n 'avocado_notebook_ragul.ipynb',\n 'pipeline test.ipynb',\n 'pyctfsglib.py',\n '__pycache__']"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show files in current directory\n",
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DataBatch</th>\n      <th>Date</th>\n      <th>TotalVolume</th>\n      <th>4046</th>\n      <th>4225</th>\n      <th>4770</th>\n      <th>TotalBags</th>\n      <th>SmallBags</th>\n      <th>LargeBags</th>\n      <th>XLargeBags</th>\n      <th>type</th>\n      <th>region</th>\n      <th>AveragePrice</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>2016-11-06</td>\n      <td>183542.31</td>\n      <td>98949.98</td>\n      <td>22891.61</td>\n      <td>95.00</td>\n      <td>61605.72</td>\n      <td>43571.99</td>\n      <td>17499.01</td>\n      <td>534.72</td>\n      <td>conventional</td>\n      <td>NewOrleansMobile</td>\n      <td>1.49</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24</td>\n      <td>2017-07-16</td>\n      <td>224434.92</td>\n      <td>42951.31</td>\n      <td>120360.02</td>\n      <td>131.85</td>\n      <td>60991.74</td>\n      <td>53141.81</td>\n      <td>3621.04</td>\n      <td>4228.89</td>\n      <td>conventional</td>\n      <td>HarrisburgScranton</td>\n      <td>1.38</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>51</td>\n      <td>2015-01-04</td>\n      <td>3846.69</td>\n      <td>1500.15</td>\n      <td>938.35</td>\n      <td>0.00</td>\n      <td>1408.19</td>\n      <td>1071.35</td>\n      <td>336.84</td>\n      <td>0.00</td>\n      <td>organic</td>\n      <td>Atlanta</td>\n      <td>1.76</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22</td>\n      <td>2015-07-26</td>\n      <td>91825.07</td>\n      <td>1679.28</td>\n      <td>45615.48</td>\n      <td>741.77</td>\n      <td>43788.54</td>\n      <td>43788.54</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>conventional</td>\n      <td>BuffaloRochester</td>\n      <td>1.39</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50</td>\n      <td>2015-01-11</td>\n      <td>54644.32</td>\n      <td>1491.88</td>\n      <td>33759.12</td>\n      <td>1325.17</td>\n      <td>18068.15</td>\n      <td>12165.94</td>\n      <td>5902.21</td>\n      <td>0.00</td>\n      <td>conventional</td>\n      <td>Pittsburgh</td>\n      <td>1.54</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    DataBatch        Date  TotalVolume      4046       4225     4770  \\\nid                                                                     \n0           7  2016-11-06    183542.31  98949.98   22891.61    95.00   \n1          24  2017-07-16    224434.92  42951.31  120360.02   131.85   \n2          51  2015-01-04      3846.69   1500.15     938.35     0.00   \n3          22  2015-07-26     91825.07   1679.28   45615.48   741.77   \n4          50  2015-01-11     54644.32   1491.88   33759.12  1325.17   \n\n    TotalBags  SmallBags  LargeBags  XLargeBags          type  \\\nid                                                              \n0    61605.72   43571.99   17499.01      534.72  conventional   \n1    60991.74   53141.81    3621.04     4228.89  conventional   \n2     1408.19    1071.35     336.84        0.00       organic   \n3    43788.54   43788.54       0.00        0.00  conventional   \n4    18068.15   12165.94    5902.21        0.00  conventional   \n\n                region  AveragePrice  \nid                                    \n0     NewOrleansMobile          1.49  \n1   HarrisburgScranton          1.38  \n2              Atlanta          1.76  \n3     BuffaloRochester          1.39  \n4           Pittsburgh          1.54  "
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csvs\n",
    "import pandas as pd\n",
    "df = pd.read_csv('avocado-train.csv', index_col='id')\n",
    "df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dealing with Missing Values ########################################################\n",
    "# https://www.kaggle.com/alexisbcook/missing-values\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=10, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)\n",
    "\n",
    "def dropColumns(X_train, X_valid):\n",
    "    # Get names of columns with missing values\n",
    "    cols_with_missing = [col for col in X_train.columns\n",
    "                        if X_train[col].isnull().any()]\n",
    "\n",
    "    # Drop columns in training and validation data\n",
    "    reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "    reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n",
    "    return reduced_X_train, reduced_X_valid\n",
    "\n",
    "\n",
    "def imputing(X_train, X_valid):\n",
    "    # Imputation\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    my_imputer = SimpleImputer()\n",
    "    imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "    imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "    # Imputation removed column names; put them back\n",
    "    imputed_X_train.columns = X_train.columns\n",
    "    imputed_X_valid.columns = X_valid.columns\n",
    "    return imputed_X_train, imputed_X_valid\n",
    "\n",
    "def imputePlus(X_train, X_valid):\n",
    "    X_train_plus = X_train.copy()\n",
    "    X_valid_plus = X_valid.copy()\n",
    "\n",
    "    # Make new columns indicating what will be imputed\n",
    "    # Get names of columns with missing values\n",
    "    cols_with_missing = [col for col in X_train.columns\n",
    "                        if X_train[col].isnull().any()]\n",
    "    for col in cols_with_missing:\n",
    "        X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
    "        X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n",
    "\n",
    "    # Imputation\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    my_imputer = SimpleImputer()\n",
    "    imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n",
    "    imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n",
    "\n",
    "    # Imputation removed column names; put them back\n",
    "    imputed_X_train_plus.columns = X_train_plus.columns\n",
    "    imputed_X_valid_plus.columns = X_valid_plus.columns\n",
    "    return imputed_X_train_plus, imputed_X_valid_plus\n",
    "\n",
    "### Dealing with Categorial Variables ##################################################\n",
    "def getCategories(X_train):\n",
    "    # Get list of categorical variables\n",
    "    s = (X_train.dtypes == 'object')\n",
    "    object_cols = list(s[s].index)\n",
    "    return object_cols\n",
    "\n",
    "def dropCategories(X_train, X_valid,object_cols = getCategories(X_train)):\n",
    "    object_cols = getCategories(X_train)\n",
    "    drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "    drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
    "    return drop_X_train, drop_X_valid\n",
    "\n",
    "# Label Encoding\n",
    "def labelEncoding(X_train, X_valid,object_cols = getCategories(X_train)):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    # Make copy to avoid changing original data \n",
    "    label_X_train = X_train.copy()\n",
    "    label_X_valid = X_valid.copy()\n",
    "\n",
    "    # Apply label encoder to each column with categorical data\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in object_cols:\n",
    "        label_X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "        label_X_valid[col] = label_encoder.transform(X_valid[col])\n",
    "\n",
    "    return label_X_train, label_X_valid\n",
    "\n",
    "### One Hot Encoding\n",
    "def oneHotEncoding(X_train, X_valid,object_cols = getCategories(X_train)):\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    # Apply one-hot encoder to each column with categorical data\n",
    "    OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "    OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
    "\n",
    "    # One-hot encoding removed index; put it back\n",
    "    OH_cols_train.index = X_train.index\n",
    "    OH_cols_valid.index = X_valid.index\n",
    "\n",
    "    # Remove categorical columns (will replace with one-hot encoding)\n",
    "    num_X_train = X_train.drop(object_cols, axis=1)\n",
    "    num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "    # Add one-hot encoded columns to numerical features\n",
    "    OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "    OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "    return OH_X_train, OH_X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "training split:  8941 ; test split:  3833\n"
    }
   ],
   "source": [
    "# Convert strings to numbers\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "# Clean Data\n",
    "#import datetime as dt\n",
    "#df.Date = [dt.date.fromisoformat(x).toordinal() for x in df.Date]\n",
    "\n",
    "c = [\"DataBatch\",'TotalVolume',\"4046\",\"4225\",\"4770\",\"TotalBags\",\"SmallBags\",\"LargeBags\",\"XLargeBags\",\"AveragePrice\"]\n",
    "'''\n",
    "for column in c:\n",
    "    df[column] = pd.to_numeric(df[column])\n",
    "'''\n",
    "# Select data for learning\n",
    "features = c[:-1]+[\"type\",\"region\"]\n",
    "X = df[features]\n",
    "Y = df[\"AveragePrice\"]\n",
    "\n",
    "# Split training into some for training and some for testing\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#TODO TODO TODO TODO TODO TODO TODO TODO\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)#, random_state=42)\n",
    "print(\"training split: \", len(X_train), \"; test split: \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the data!\n",
    "#df.head()\n",
    "X_train, X_test = labelEncoding(X_train, X_test)#, ['type'])\n",
    "X_train, X_test = imputePlus(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DataBatch</th>\n      <th>TotalVolume</th>\n      <th>4046</th>\n      <th>4225</th>\n      <th>4770</th>\n      <th>TotalBags</th>\n      <th>SmallBags</th>\n      <th>LargeBags</th>\n      <th>XLargeBags</th>\n      <th>type</th>\n      <th>region</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.0</td>\n      <td>185141.54</td>\n      <td>3659.19</td>\n      <td>50387.09</td>\n      <td>836.20</td>\n      <td>130259.06</td>\n      <td>119351.93</td>\n      <td>10907.13</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22.0</td>\n      <td>1509.80</td>\n      <td>781.44</td>\n      <td>199.22</td>\n      <td>0.00</td>\n      <td>529.14</td>\n      <td>516.67</td>\n      <td>12.47</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>44.0</td>\n      <td>2373.09</td>\n      <td>1437.69</td>\n      <td>715.40</td>\n      <td>0.00</td>\n      <td>220.00</td>\n      <td>220.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>44.0</td>\n      <td>121048.70</td>\n      <td>79840.95</td>\n      <td>10684.39</td>\n      <td>1447.09</td>\n      <td>29076.27</td>\n      <td>21773.29</td>\n      <td>7302.98</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>46.0</td>\n      <td>246616.27</td>\n      <td>64858.54</td>\n      <td>116792.77</td>\n      <td>65.38</td>\n      <td>64899.58</td>\n      <td>17633.33</td>\n      <td>47266.25</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>52.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   DataBatch  TotalVolume      4046       4225     4770  TotalBags  SmallBags  \\\n0        2.0    185141.54   3659.19   50387.09   836.20  130259.06  119351.93   \n1       22.0      1509.80    781.44     199.22     0.00     529.14     516.67   \n2       44.0      2373.09   1437.69     715.40     0.00     220.00     220.00   \n3       44.0    121048.70  79840.95   10684.39  1447.09   29076.27   21773.29   \n4       46.0    246616.27  64858.54  116792.77    65.38   64899.58   17633.33   \n\n   LargeBags  XLargeBags  type  region  \n0   10907.13         0.0   1.0    25.0  \n1      12.47         0.0   1.0    14.0  \n2       0.00         0.0   1.0    14.0  \n3    7302.98         0.0   0.0    20.0  \n4   47266.25         0.0   1.0    52.0  "
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()\n",
    "#y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 8941 samples\n8941/8941 [==============================] - 3s 384us/sample - loss: 38835368008.8948\nFinished training the model\n"
    }
   ],
   "source": [
    "# Units refers to the number of neurons\n",
    "l0 = tf.keras.layers.Dense(units=len(X_train.columns), input_shape=[len(X_train.columns)])\n",
    "l1 = tf.keras.layers.Dense(units=len(X_train.columns), input_shape=[len(X_train.columns)])\n",
    "l2 = tf.keras.layers.Dense(units=len(X_train.columns), input_shape=[len(X_train.columns)])\n",
    "le = tf.keras.layers.Dense(units=1)\n",
    "model = tf.keras.Sequential([l0, l1, l2, le])\n",
    "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "model.fit(X_train, Y_train, epochs=1, verbose=True)#,batch_size=1, callbacks=[earlystop_callback])\n",
    "\n",
    "#print(model.predict(np.array([[100,101], [9,8]])))\n",
    "print(\"Finished training the model\")\n",
    "#print(\"These are the l0 variables: {}\".format(l0.get_weights()))\n",
    "#print(\"These are the l1 variables: {}\".format(l1.get_weights()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "100/100 [==============================] - 0s 2ms/step - loss: 2985575168.0000\n"
    },
    {
     "data": {
      "text/plain": "2985575168.0"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfmodel = model\n",
    "results = tfmodel.evaluate(X_test,Y_test,batch_size=128, steps=100)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n                      max_samples=None, min_impurity_decrease=0.0,\n                      min_impurity_split=None, min_samples_leaf=1,\n                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n                      n_estimators=1000, n_jobs=None, oob_score=False,\n                      random_state=None, verbose=0, warm_start=False)\n"
    }
   ],
   "source": [
    "# Sci Kit Learn! Scientific Computing library for python\n",
    "from sklearn import *\n",
    "# Pick the regression model we want to use\n",
    "\n",
    "import sklearn.tree as tree\n",
    "models = [\n",
    "    #tree.DecisionTreeRegressor(random_state=2020),\n",
    "    ensemble.RandomForestRegressor(random_state=None, n_estimators=1000)\n",
    "]\n",
    "\n",
    "currScore = 0\n",
    "model = None\n",
    "for i in models:\n",
    "    print(i)\n",
    "    i.fit(X_train,Y_train)\n",
    "    score = i.score(X_test,Y_test)\n",
    "    if score > currScore:\n",
    "        model = i\n",
    "        currScore = score\n",
    "\n",
    "# https://www.kdnuggets.com/2016/10/beginners-guide-neural-networks-python-scikit-learn.html/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.8176263615799223"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model\n",
    "model.score(X_test, Y_test) #TODO TODO TODO TODO TODO TODO TODO TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict for Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Data\n",
    "MyDataFrame = pd.read_csv('avocado-test.csv', index_col='id')\n",
    "# Drops missing values \n",
    "#MyDataFrame.dropna()\n",
    "# Convert strings to numbers\n",
    "\n",
    "MyDataFrame[\"Date\"] = pd.to_datetime(MyDataFrame[\"Date\"])\n",
    "#MyDataFrame.Date = [dt.date.fromisoformat(x).toordinal() for x in df.Date]\n",
    "c = ['TotalVolume',\"4046\",\"4225\",\"4770\",\"TotalBags\",\"SmallBags\",\"LargeBags\",\"XLargeBags\"]#,\"AveragePrice\"]\n",
    "#for column in c:\n",
    "#    MyDataFrame[column] = pd.to_numeric(MyDataFrame[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DataBatch</th>\n      <th>TotalVolume</th>\n      <th>4046</th>\n      <th>4225</th>\n      <th>4770</th>\n      <th>TotalBags</th>\n      <th>SmallBags</th>\n      <th>LargeBags</th>\n      <th>XLargeBags</th>\n      <th>type</th>\n      <th>region</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21.0</td>\n      <td>28969.34</td>\n      <td>80.77</td>\n      <td>27361.91</td>\n      <td>0.00</td>\n      <td>1526.66</td>\n      <td>1526.66</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19.0</td>\n      <td>322962.89</td>\n      <td>5632.85</td>\n      <td>242365.82</td>\n      <td>2441.56</td>\n      <td>72522.66</td>\n      <td>22942.48</td>\n      <td>46083.51</td>\n      <td>3496.67</td>\n      <td>0.0</td>\n      <td>30.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>49.0</td>\n      <td>155334.45</td>\n      <td>3657.79</td>\n      <td>74068.65</td>\n      <td>0.00</td>\n      <td>77608.01</td>\n      <td>27302.29</td>\n      <td>50305.72</td>\n      <td>0.00</td>\n      <td>1.0</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12.0</td>\n      <td>10231.74</td>\n      <td>341.89</td>\n      <td>8519.00</td>\n      <td>0.00</td>\n      <td>1370.85</td>\n      <td>303.33</td>\n      <td>1067.52</td>\n      <td>0.00</td>\n      <td>1.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10.0</td>\n      <td>10652.02</td>\n      <td>6905.95</td>\n      <td>39.52</td>\n      <td>0.00</td>\n      <td>3706.55</td>\n      <td>3706.55</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.0</td>\n      <td>18.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   DataBatch  TotalVolume     4046       4225     4770  TotalBags  SmallBags  \\\n0       21.0     28969.34    80.77   27361.91     0.00    1526.66    1526.66   \n1       19.0    322962.89  5632.85  242365.82  2441.56   72522.66   22942.48   \n2       49.0    155334.45  3657.79   74068.65     0.00   77608.01   27302.29   \n3       12.0     10231.74   341.89    8519.00     0.00    1370.85     303.33   \n4       10.0     10652.02  6905.95      39.52     0.00    3706.55    3706.55   \n\n   LargeBags  XLargeBags  type  region  \n0       0.00        0.00   1.0     8.0  \n1   46083.51     3496.67   0.0    30.0  \n2   50305.72        0.00   1.0    15.0  \n3    1067.52        0.00   1.0     9.0  \n4       0.00        0.00   1.0    18.0  "
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select features\n",
    "XforPredictions =  MyDataFrame[features]#None #TODO TODO TODO TODO TODO TODO TODO TODO\n",
    "\n",
    "\n",
    "X_train, X_test = labelEncoding(X, XforPredictions)\n",
    "X_train, X_test = imputePlus(X_train ,X_test)\n",
    "\n",
    "#XforPredictions.head()\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Predictions: [1.97224 1.46453 1.28572 ... 1.4239  1.97609 1.65349]\n"
    }
   ],
   "source": [
    "# Make Predictions!\n",
    "#model.fit(X,Y)\n",
    "if False:\n",
    "    yPredictions = tfmodel.predict(X_test)\n",
    "    #If Using tfmodel\n",
    "    predictions = []\n",
    "    for i in yPredictions:\n",
    "        predictions.append(i[0])\n",
    "    yPredictions = predictions\n",
    "else:\n",
    "    yPredictions = model.predict(X_test)\n",
    "    print(\"Predictions:\", yPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "id  AveragePrice\n0        0       1.97224\n1        1       1.46453\n2        2       1.28572\n3        3       1.58024\n4        4       1.48246\n...    ...           ...\n5470  5470       1.70463\n5471  5471       1.37585\n5472  5472       1.42390\n5473  5473       1.97609\n5474  5474       1.65349\n\n[5475 rows x 2 columns]\n"
    }
   ],
   "source": [
    "# Save to CSV File!\n",
    "XforPredictions =  MyDataFrame[features]\n",
    "output = pd.DataFrame({'id': XforPredictions.index, 'AveragePrice': yPredictions})\n",
    "output.to_csv('avocado-submission.csv', index=False)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Downloaded pyctfsglib.py: True\n"
    }
   ],
   "source": [
    "# Download CTFSG Grader Libraries\n",
    "import urllib.request, os\n",
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/alttablabs/ctfsg-utils/master/pyctfsglib.py', './pyctfsglib.py')\n",
    "print('Downloaded pyctfsglib.py:', 'pyctfsglib.py' in os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "DSGraderClient: Successfully Connected!\n[SERVER] MOTD: CHECK your USER_TOKEN and GRADER_URL HTTP address! I'm AVOCADO_PRICE GRADER_5021d39ae191\n"
    }
   ],
   "source": [
    "# Connect to graders\n",
    "import pyctfsglib as ctfsg\n",
    "import random\n",
    "\n",
    "USER_TOKEN = \"MXhtGfdjdsUfiEKTHHEuVGohZESBdMiHrFkmYqNqIFfcWOHGvcubvHJvnxpAqRMh\" # You need to fill this up\n",
    "GRADER_URL = random.choice([\n",
    "\"http://challenges.csdc20t.ctf.sg:30001/\", \"http://challenges.csdc20t.ctf.sg:30002/\"\n",
    "])\n",
    "grader = ctfsg.DSGraderClient(GRADER_URL, USER_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "ProofOfWork Challenge =>  ('CTFSGRB05ce4aec1cc8e0394bee379b916c7e67', 22)\nProofOfWork Answer Found! =>  2022964\n"
    },
    {
     "data": {
      "text/plain": "'{\"challenge\":{\"name\":\"Avocado Prices\"},\"id\":\"ck8n7jqia767v0702ggqodww9\",\"status\":\"PARTIALLY_CORRECT\",\"multiplier\":0.8279,\"submittedBy\":{\"username\":\"nyjc-1\"},\"createdAt\":\"2020-04-05T15:35:40Z\"}'"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.submitFile('avocado-submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}